{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7hhv2Ynp/ZmFBYs3uPWJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumeyyeSuslu/regression/blob/main/sparkH2Odummyautoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu ornek spark uzerinde h2o ve sparkling water kullanarak autoencoder ve lineer regression algoritmasını kullanmaktadır.\n",
        "\n",
        "\n",
        "**BU ornekte h20 kurulum ve init calisti, deep learning model olusturuldu dakat regression basarisiz. Autoencoder featurelari restructure ettigi icin x y z koordinatlarini da bozuyor. Ayrica rmse kullanimini yapamadik. Scriptin alti (print rmse den sonrasi)tamamen baska ornekten kopyalandi calistirilmadi.**\n"
      ],
      "metadata": {
        "id": "RS-l-NGWvuY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sQJmzzC3_PPv",
        "outputId": "5729b3be-f6c2-42a8-fb6d-183538ed9adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "\r0% [Waiting for headers] [Connecting to cloud.r-project.org (13.224.189.127)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "\r                                                                               \rHit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "\r0% [Connected to cloud.r-project.org (13.224.189.127)] [Connected to developer.\r                                                                               \rHit:7 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Reading package lists... Done\n",
            "openjdk version \"1.8.0_352\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_352-8u352-ga-1~20.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h2o<3.40.0.0\n",
            "  Downloading h2o-3.38.0.4.tar.gz (177.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from h2o<3.40.0.0) (2.25.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from h2o<3.40.0.0) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from h2o<3.40.0.0) (0.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->h2o<3.40.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->h2o<3.40.0.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->h2o<3.40.0.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->h2o<3.40.0.0) (2.10)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.38.0.4-py2.py3-none-any.whl size=177628739 sha256=8d9fa24de545901b7af7b5d69061bf95926c114ab2ff2e9c7f0127894b74f174\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1d/65/39927b5984bde22f615b4c6e9a8ee98ea4abf1acb5926623ff\n",
            "Successfully built h2o\n",
            "Installing collected packages: h2o\n",
            "  Attempting uninstall: h2o\n",
            "    Found existing installation: h2o 3.40.0.1\n",
            "    Uninstalling h2o-3.40.0.1:\n",
            "      Successfully uninstalled h2o-3.40.0.1\n",
            "Successfully installed h2o-3.38.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h2o"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h2o-pysparkling-3.3 in /usr/local/lib/python3.8/dist-packages (3.38.0.4.post1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from h2o-pysparkling-3.3) (0.8.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from h2o-pysparkling-3.3) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from h2o-pysparkling-3.3) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->h2o-pysparkling-3.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->h2o-pysparkling-3.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->h2o-pysparkling-3.3) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->h2o-pysparkling-3.3) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "!pip install pyspark\n",
        "!pip install 'h2o<3.40.0.0'\n",
        "!pip install h2o-pysparkling-3.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "      #ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZzZ1`1"
      ],
      "metadata": {
        "id": "clYYe3QlBE8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export SPARK_LOCAL_IP='127.0.0.1'\n",
        "!export MASTER='local[*]'"
      ],
      "metadata": {
        "id": "xXuQkC3LQzyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar xvf dummygeometryJSON.tar.gz \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!tar xvf /content/drive/MyDrive/dummygeometryJSON.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewcYfEFM9NoE",
        "outputId": "acd0c858-5482-4804-fdb0-736032dffa93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "dummygeometry.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark Session, Pipeline, Functions, and Metrics\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext, SparkSession\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        " \n",
        "from pyspark.sql.functions import rand\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "import pyspark.sql.functions as F\n",
        "import h2o\n",
        "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
        "\n",
        "from pysparkling import *"
      ],
      "metadata": {
        "id": "MrHzAal5TtHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext\n"
      ],
      "metadata": {
        "id": "LzKoQ8D7RS7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start H2O cluster\n",
        "h2o.init()\n",
        "h2oContext =  H2OContext.getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RBSHKJGjVFEl",
        "outputId": "91fd0954-1f84-4bca-d7b6-9b543e101c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"1.8.0_352\"; OpenJDK Runtime Environment (build 1.8.0_352-8u352-ga-1~20.04-b08); OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\n",
            "  Starting server from /usr/local/lib/python3.8/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmp5yf62zw7\n",
            "  JVM stdout: /tmp/tmp5yf62zw7/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmp5yf62zw7/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  ----------------------------------\n",
              "H2O_cluster_uptime:         02 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.38.0.4\n",
              "H2O_cluster_version_age:    1 month and 7 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_58vhxn\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    2.813 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.8.10 final\n",
              "--------------------------  ----------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>02 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.38.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 7 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_58vhxn</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>2.813 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.8.10 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to H2O server at http://6356f88bbba4:54325 ... successful.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  ----------------------------------------\n",
              "H2O_cluster_uptime:         19 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.38.0.4\n",
              "H2O_cluster_version_age:    1 month and 7 days\n",
              "H2O_cluster_name:           sparkling-water-root_local-1676227128042\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    804 Mb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://6356f88bbba4:54325\n",
              "H2O_connection_proxy:       null\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.8.10 final\n",
              "--------------------------  ----------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>19 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.38.0.4</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 7 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>sparkling-water-root_local-1676227128042</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>804 Mb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://6356f88bbba4:54325</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>null</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.8.10 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sparkling Water Context:\n",
            " * Sparkling Water Version: 3.38.0.4-1-3.3\n",
            " * H2O name: sparkling-water-root_local-1676227128042\n",
            " * cluster size: 1\n",
            " * list of used nodes:\n",
            "  (executorId, host, port)\n",
            "  ------------------------\n",
            "  (0,172.28.0.12,54323)\n",
            "  ------------------------\n",
            "\n",
            "  Open H2O Flow in browser: http://6356f88bbba4:54325 (CMD + click in Mac OSX)\n",
            "\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json('dummygeometry.json')\n",
        "# Select the relevant columns\n",
        "input_cols = ['mach','aoa','CoordinateX', 'CoordinateY','CoordinateZ','zone']\n",
        "output_col = \"Pressure Coefficient\"\n",
        "spark_df = df.select(input_cols + [output_col])\n",
        "# Convert Spark DataFrame to H2OFrame\n",
        "h2oFrame = h2oContext.asH2OFrame(spark_df)\n"
      ],
      "metadata": {
        "id": "UJaKRfpRO3F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "train, valid = h2oFrame.split_frame(ratios=[0.8], seed=123)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = H2OAutoEncoderEstimator(\n",
        "  activation=\"Tanh\",\n",
        "  hidden=[10, 5],\n",
        "  epochs=100,\n",
        "  seed=123\n",
        ")\n",
        "\n",
        "# Train the autoencoder model on the training set\n",
        "autoencoder.train(\n",
        "  x=train.names,\n",
        "  training_frame=train,\n",
        "  validation_frame=valid\n",
        ")\n",
        "\n",
        "# Make predictions on the validation set\n",
        "predictions = autoencoder.predict(valid)\n",
        "\n",
        "# Calculate RMSE\n",
        "\n",
        "y_true = valid[\"Pressure Coefficient\"]\n",
        "y_pred = predictions[\"predict\"]\n",
        "\n",
        "\n",
        "# Stop H2O cluster\n",
        "#h2o.shutdown()\n"
      ],
      "metadata": {
        "id": "wjL5S4uPZHdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b71182-ea54-4b8b-c071-727d6904c5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
            "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.rmse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "rHQN8UMx0diP",
        "outputId": "d00d5d41-d30a-4848-c56b-699cb1dccddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-80f68481ddae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'H2OFrame' object has no attribute 'rmse'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='pressure', predictionCol='predict')\n",
        "# Evaluate the performance of the autoencoder on the test data\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"RMSE:\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Y-KwgIoJxebW",
        "outputId": "87547cc0-8d78-41a7-c71a-7dbdfe0f2c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1817353c00e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pressure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluate the performance of the autoencoder on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'H2OFrame' object has no attribute '_jdf'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the autoencoder on the training data\n",
        "model = autoencoder.fit(train)\n",
        "\n",
        "# Apply the autoencoder to the test data\n",
        "encoded_test_data = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='pressure', predictionCol='latent_representation')\n",
        "\n",
        "# Evaluate the performance of the autoencoder on the test data\n",
        "rmse = evaluator.evaluate(encoded_test_data)\n",
        "print(\"RMSE:\", rmse)\n",
        "\n"
      ],
      "metadata": {
        "id": "9rtC7lIyvvwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fp5Pb9yW0_q",
        "outputId": "49da2c15-945d-4135-dece-dd2a312cada7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  reconstr_mach    reconstr_aoa    reconstr_CoordinateX    reconstr_CoordinateY    reconstr_CoordinateZ    reconstr_zone    reconstr_Pressure Coefficient\n",
            "       0.597561         9.96841                 11.8784                -1.6593                 0.139004        0.0761089                        -0.129142\n",
            "       0.59667          9.96257                 11.867                 -1.67013                0.138275        0.0707741                        -0.129234\n",
            "       0.5968           9.96381                 11.8863                -1.68741                0.142244        0.0699384                        -0.129682\n",
            "       0.599889         9.98218                 12.0316                -1.52655                0.134491        0.0961401                        -0.125225\n",
            "       0.598218         9.97144                 11.9567                -1.60099                0.141096        0.0949467                        -0.127685\n",
            "       0.599966         9.9813                  12.0382                -1.48507                0.134217        0.114713                         -0.124563\n",
            "       0.597539         9.96902                 12.0222                -1.67251                0.149603        0.070308                         -0.128675\n",
            "       0.597503         9.97028                 11.9844                -1.7674                 0.161872        0.0677255                        -0.131797\n",
            "       0.599157         9.97971                 12.0925                -1.68946                0.165461        0.094731                         -0.129981\n",
            "       0.59713          9.96707                 12.1089                -1.70082                0.158816        0.0649101                        -0.128923\n",
            "[75399 rows x 7 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG_v2iMnZGst",
        "outputId": "f4b24817-4e5f-4e33-8f2c-c53e2ea0a578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  mach    aoa    CoordinateX    CoordinateY    CoordinateZ    zone    Pressure Coefficient\n",
            "   0.6     10        11.791        -1.66806       0.260443       0              -0.063004\n",
            "   0.6     10        11.7686       -1.69392       0.26584        0               0.0328851\n",
            "   0.6     10        11.8017       -1.71349       0.26528        0               0.0129717\n",
            "   0.6     10        11.9673       -1.47686       0.256793       0              -0.311165\n",
            "   0.6     10        11.8441       -1.56003       0.294707       0              -0.137517\n",
            "   0.6     10        11.9211       -1.39          0.297938       0              -0.318486\n",
            "   0.6     10        11.9872       -1.69439       0.260765       0              -0.0815489\n",
            "   0.6     10        11.9671       -1.80103       0.265409       0              -0.0937527\n",
            "   0.6     10        12.0598       -1.65057       0.299872       0              -0.276396\n",
            "   0.6     10        12.106        -1.73743       0.267299       0              -0.0554022\n",
            "[75399 rows x 7 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Autoencoder\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Assemble the features into a single column\n",
        "assembler = VectorAssembler(inputCols=['mach','aoa','CoordinateX', 'CoordinateY','CoordinateZ','zone'], outputCol=\"features\")\n",
        "data = assembler.transform(df)\n",
        "\n",
        "# Initialize the autoencoder\n",
        "autoencoder = Autoencoder(inputCol='features', outputCol='latent_representation', layers=[3, 2, 3])\n",
        "\n",
        "# Split the data into training and test datasets\n",
        "training_data, test_data = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Train the autoencoder on the training data\n",
        "model = autoencoder.fit(training_data)\n",
        "\n",
        "# Apply the autoencoder to the test data\n",
        "encoded_test_data = model.transform(test_data)\n",
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='pressure', predictionCol='latent_representation')\n",
        "\n",
        "# Evaluate the performance of the autoencoder on the test data\n",
        "rmse = evaluator.evaluate(encoded_test_data)\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "# Compute the RMSE between the original pressure values and the reconstructed pressure values\n",
        "\n"
      ],
      "metadata": {
        "id": "S5IQNVnFq6WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.summary().show()"
      ],
      "metadata": {
        "id": "LhT9obTIS-n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# filter rows where zone is 3 or 0 and mach is less than 0.8 and CoordinateZ is less than or equal to 0.26\n",
        "filtered_df = df.filter((col(\"zone\") == 3) | (col(\"zone\") == 0) & (col(\"mach\") < 0.8) & (col(\"CoordinateZ\") <= 0.26))"
      ],
      "metadata": {
        "id": "IWuJj9jV4eJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.summary().show()"
      ],
      "metadata": {
        "id": "RyacrCDOCH-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset randomly into 80% for training and 20% for testing. Passing a seed for deterministic behavior\n",
        "train_data, test_data = filtered_df.randomSplit([0.8, 0.2], seed = 0)"
      ],
      "metadata": {
        "id": "nUnlTKVQpi6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorAssembler= VectorAssembler(inputCols=['mach','aoa','CoordinateX', 'CoordinateY','CoordinateZ' ],outputCol='features')\n",
        "\n",
        "gbt = GBTRegressor(featuresCol='features',labelCol='Pressure')"
      ],
      "metadata": {
        "id": "cDw-JOhsbYP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a grid of hyperparameters to test:\n",
        "#  - maxDepth: maximum depth of each decision tree \n",
        "#  - maxIter: iterations, or the total number of trees \n",
        "paramGrid = ParamGridBuilder()\\\n",
        "  .addGrid(gbt.maxDepth, [2, 5])\\\n",
        "  .addGrid(gbt.maxIter, [10, 100])\\\n",
        "  .build()\n",
        " \n",
        "# Define an evaluation metric.  The CrossValidator compares the true labels with predicted values for each combination of parameters, and calculates this value to determine the best model.\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n",
        " \n",
        "# Declare the CrossValidator, which performs the model tuning.\n",
        "cv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid)\n"
      ],
      "metadata": {
        "id": "0R9DFdpmoEYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipeline = Pipeline(stages=[vectorAssembler, cv])\n",
        "\n",
        "# Train model.  This also runs the indexer.\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"Pressure\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
        "\n",
        "rfModel = model.stages[0]\n",
        "print(rfModel)  # summary only"
      ],
      "metadata": {
        "id": "yIFVsoklPn9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}