{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAIhzvDrt8ki10XPsueuUF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumeyyeSuslu/regression/blob/main/sparkdummyGBR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu ornek spark uzerinde SparkML tarafından dogrudan desteklenen GBT regression algoritmasını kullanmaktadır."
      ],
      "metadata": {
        "id": "RS-l-NGWvuY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQJmzzC3_PPv",
        "outputId": "ed111c4f-b4ab-4088-f288-6164f686ec87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,924 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,291 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,448 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [991 kB]\n",
            "Fetched 7,993 kB in 2s (3,210 kB/s)\n",
            "Reading package lists... Done\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_352\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_352-8u352-ga-1~20.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=cf68a1a50c0f6ba86d5d4d9442c332380bd7c80e651b2cbb7302f4024a592fe3\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "      #ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZzZ1`1"
      ],
      "metadata": {
        "id": "clYYe3QlBE8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!tar xvf dummygeometryJSON.tar.gz \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!tar xvf /content/drive/MyDrive/dummygeometryJSON.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewcYfEFM9NoE",
        "outputId": "c98e3ca9-16f6-48a1-f220-d44891b7ff07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dummygeometry.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark Session, Pipeline, Functions, and Metrics\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext, SparkSession\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StandardScaler, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        " \n",
        "from pyspark.sql.functions import rand\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "import pyspark.sql.functions as F"
      ],
      "metadata": {
        "id": "MrHzAal5TtHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "LzKoQ8D7RS7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json('dummygeometry.json')\n"
      ],
      "metadata": {
        "id": "UJaKRfpRO3F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhT9obTIS-n_",
        "outputId": "6bd27785-53eb-44ec-cd76-e402b688aff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+--------------------+-------------------+------------------+--------------------+----------------------+----------------------+----------------------+------------------+------+-------------------+------------------+\n",
            "|summary|      CoordinateX|         CoordinateY|        CoordinateZ|          Pressure|Pressure Coefficient|X Component Wall Shear|Y Component Wall Shear|Z Component Wall Shear|               aoa|  beta|               mach|              zone|\n",
            "+-------+-----------------+--------------------+-------------------+------------------+--------------------+----------------------+----------------------+----------------------+------------------+------+-------------------+------------------+\n",
            "|  count|           378068|              378068|             378068|            378068|              378068|                378068|                378068|                378068|            378068|378068|             378068|            378068|\n",
            "|   mean|7.276900698086052|-0.00225729663392...|0.14448217478839603|-4396.849710108307|-0.10641995033369032|      68.2302369526018|  0.006208948887269837|     2.667406321774552|5.5992837267369895|   0.0| 0.6498799254582421|2.3409518922521872|\n",
            "| stddev|2.663581341014283|  1.8126633579548141|0.38468189830893534|12095.664197927554| 0.24978343707558223|    58.481924945976864|      24.2142072143192|    10.518564865742228| 3.441065012874294|   0.0|0.29581517477443703|1.3588954005607834|\n",
            "|    min|              0.0|       -3.7295095921|      -0.7023435235|     -72765.828125|       -2.0539984703|        -61.5772743225|       -183.9320831299|        -71.6020736694|               0.0|   0.0|        0.200000003|               0.0|\n",
            "|    25%|     5.5350599289|        -0.810962975|      -0.0484224036|  -6282.8271484375|       -0.1874662191|         10.1054191589|         -3.6512491703|         -0.9602567554|               4.0|   0.0|        0.200000003|               1.0|\n",
            "|    50%|      7.172624588|            2.006E-6|        0.075365752|   -655.5162963867|       -0.0609800071|         56.4783744812|         -0.0034240463|          0.4755927026|               6.0|   0.0|       0.6000000238|               2.0|\n",
            "|    75%|     8.6239109039|         0.799223423|       0.2737093568|    307.4469299316|        0.0259637088|        105.9792480469|          3.6705164909|           4.261235714|               8.0|   0.0|       0.8000000119|               4.0|\n",
            "|    max|    13.4100961685|        3.7295095921|       2.1686079502|     41284.8359375|        0.5896502137|        389.7946166992|        197.5114440918|         172.018081665|              10.0|   0.0|                1.0|               5.0|\n",
            "+-------+-----------------+--------------------+-------------------+------------------+--------------------+----------------------+----------------------+----------------------+------------------+------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# filter rows where zone is 3 or 0 and mach is less than 0.8 and CoordinateZ is less than or equal to 0.26\n",
        "filtered_df = df.filter((col(\"zone\") == 3) | (col(\"zone\") == 0) & (col(\"mach\") < 0.8) & (col(\"CoordinateZ\") <= 0.26))"
      ],
      "metadata": {
        "id": "IWuJj9jV4eJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyacrCDOCH-1",
        "outputId": "fc58f54e-5a60-4a5f-c63d-a3b5c154ef9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------------------+-------------------+------------------+--------------------+----------------------+----------------------+----------------------+------------------+-----+-------------------+------------------+\n",
            "|summary|        CoordinateX|       CoordinateY|        CoordinateZ|          Pressure|Pressure Coefficient|X Component Wall Shear|Y Component Wall Shear|Z Component Wall Shear|               aoa| beta|               mach|              zone|\n",
            "+-------+-------------------+------------------+-------------------+------------------+--------------------+----------------------+----------------------+----------------------+------------------+-----+-------------------+------------------+\n",
            "|  count|              25331|             25331|              25331|             25331|               25331|                 25331|                 25331|                 25331|             25331|25331|              25331|             25331|\n",
            "|   mean| 11.303435019840103|0.5269861020928874|0.24345421626788613|-2238.403641482756|-0.05986662499080973|     80.62555853891773|  -0.44232405212977133|     2.713884216041861| 5.600331609490348|  0.0| 0.5960996512259178|2.3562038608819234|\n",
            "| stddev|0.48945390149065177|0.8121273203052204|0.03446550551877041| 7347.571147316547| 0.14320907586000442|     67.63490411479341|     7.910511996090734|    10.670939234868262|3.4399579341624253|  0.0|0.29645721320945645|1.2316553230154481|\n",
            "|    min|      10.2763280869|     -1.7043690681|       0.1752050221|   -51420.66796875|       -0.7254928946|         -32.367061615|        -39.6788749695|        -71.6020736694|               0.0|  0.0|        0.200000003|               0.0|\n",
            "|    25%|      10.9191865921|      0.1660099924|       0.2158306986|  -4014.3251953125|       -0.1367249191|         11.4840021133|         -4.2017502785|         -0.7909004688|               4.0|  0.0|        0.200000003|               3.0|\n",
            "|    50%|       11.339507103|      0.5216687322|       0.2434858531|   -453.1004333496|       -0.0711411014|          69.449760437|         -0.3382442594|           0.807612896|               6.0|  0.0|       0.6000000238|               3.0|\n",
            "|    75%|      11.6718864441|      1.1079462767|       0.2742861509|    176.4684448242|        0.0209535379|        124.7878265381|          1.4418883324|          5.5946135521|               8.0|  0.0|       0.8000000119|               3.0|\n",
            "|    max|      12.4511985779|      1.8732277155|       0.3017204106|    32477.87890625|        0.4582295716|        338.1273803711|         61.9216461182|         63.6524200439|              10.0|  0.0|                1.0|               3.0|\n",
            "+-------+-------------------+------------------+-------------------+------------------+--------------------+----------------------+----------------------+----------------------+------------------+-----+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset randomly into 80% for training and 20% for testing. Passing a seed for deterministic behavior\n",
        "train_data, test_data = filtered_df.randomSplit([0.8, 0.2], seed = 0)"
      ],
      "metadata": {
        "id": "nUnlTKVQpi6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorAssembler= VectorAssembler(inputCols=['mach','aoa','CoordinateX', 'CoordinateY','CoordinateZ' ],outputCol='features')\n",
        "\n",
        "gbt = GBTRegressor(featuresCol='features',labelCol='Pressure Coefficient')"
      ],
      "metadata": {
        "id": "cDw-JOhsbYP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a grid of hyperparameters to test:\n",
        "#  - maxDepth: maximum depth of each decision tree \n",
        "#  - maxIter: iterations, or the total number of trees \n",
        "paramGrid = ParamGridBuilder()\\\n",
        "  .addGrid(gbt.maxDepth, [2, 5])\\\n",
        "  .addGrid(gbt.maxIter, [10, 100])\\\n",
        "  .build()\n",
        " \n",
        "# Define an evaluation metric.  The CrossValidator compares the true labels with predicted values for each combination of parameters, and calculates this value to determine the best model.\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n",
        " \n",
        "# Declare the CrossValidator, which performs the model tuning.\n",
        "cv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid)\n"
      ],
      "metadata": {
        "id": "0R9DFdpmoEYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipeline = Pipeline(stages=[vectorAssembler, cv])\n",
        "\n",
        "# Train model.  This also runs the indexer.\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"Pressure Coefficient\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
        "\n",
        "rfModel = model.stages[0]\n",
        "print(rfModel)  # summary only"
      ],
      "metadata": {
        "id": "yIFVsoklPn9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2365586e-7ec4-47b5-f3f4-6160e52f3a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|          prediction|Pressure Coefficient|            features|\n",
            "+--------------------+--------------------+--------------------+\n",
            "| 0.14622437718023906|        0.1499677896|[0.200000003,6.0,...|\n",
            "|0.027196017252345887|        0.0386430323|[0.6000000238,0.0...|\n",
            "|  0.3105336134038018|        0.3003864884|[1.0,8.0,10.29580...|\n",
            "| 0.33042154700795867|        0.3072147369|[1.0,10.0,10.2958...|\n",
            "| 0.04124814848720778|       -0.0145418299|[0.6000000238,0.0...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Root Mean Squared Error (RMSE) on test data = 0.0374993\n",
            "VectorAssembler_cb92d48ac9ff\n"
          ]
        }
      ]
    }
  ]
}